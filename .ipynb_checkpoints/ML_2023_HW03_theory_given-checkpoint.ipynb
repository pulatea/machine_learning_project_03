{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb933eab",
   "metadata": {},
   "source": [
    "# Home Assignment No. 3: Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e21e01",
   "metadata": {},
   "source": [
    "In this part of the homework you need to solve several theoretical problems related to machine learning algorithms.\n",
    "\n",
    "* Please include your name, surname and matriculation number in the beginning of the notebook file.\n",
    "\n",
    "* Please contact Alp Eren SARI (alp.sari@unibe.ch) for questions and problems related to the assignment\n",
    "\n",
    "* For every separate problem you can get **INTERMEDIATE scores**.\n",
    "\n",
    "\n",
    "* Your solution must be **COMPLETE**, i.e. contain all required formulas/proofs/detailed explanations.\n",
    "\n",
    "\n",
    "* You must write your solution for any problem right after the words **YOUR SOLUTION**. Attaching pictures of your handwriting is allowed, but **highly discouraged**.\n",
    "\n",
    "## $\\LaTeX$ in Jupyter\n",
    "\n",
    "Jupyter has constantly improving $\\LaTeX$ support. Below are the basic methods to write **neat, tidy, and well typeset** equations in your notebooks:\n",
    "\n",
    "* to write an **inline** equation use \n",
    "```markdown\n",
    "$ you latex equation here $\n",
    "```\n",
    "\n",
    "* to write an equation, that is **displayed on a separate line** use \n",
    "```markdown\n",
    "$$ you latex equation here $$\n",
    "```\n",
    "\n",
    "* to write **cases of equations** use \n",
    "```markdown\n",
    "$$ left-hand-side = \\begin{cases}\n",
    "                     right-hand-side on line 1, & \\text{condition} \\\\\n",
    "                     right-hand-side on line 2, & \\text{condition} \\\\\n",
    "                    \\end{cases} $$\n",
    "```\n",
    "\n",
    "* to write a **block of equations** use \n",
    "```markdown\n",
    "$$ \\begin{align}\n",
    "    left-hand-side on line 1 &= right-hand-side on line 1 \\\\\n",
    "    left-hand-side on line 2 &= right-hand-side on line 2\n",
    "   \\end{align} $$\n",
    "```\n",
    "\n",
    "The **ampersand** (`&`) aligns the equations horizontally and the **double backslash**\n",
    "(`\\\\`) creates a new line."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b141d88f",
   "metadata": {},
   "source": [
    "## Task 1. Ensembling Method [4 points]\n",
    "\n",
    "Suppose that we have random variables $X_i$ for $0 \\leq i \\leq n$ with $Var(X_i) = \\sigma_i^2$. Moreover, any $X_k$ and $X_l$ are correlated by a factor of ${\\rho}_{kl}$ for any k and l. Calculate the variance of the average of these random variables as in $Z = \\frac{1}{n}\\sum\\limits_{i=0}^{n}X_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8700866c",
   "metadata": {},
   "source": [
    "$\\color{red}{\\textbf{Your Solution: }}$\n",
    "\n",
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8777db9",
   "metadata": {},
   "source": [
    "## Boosting\n",
    "\n",
    "Minimizing the loss function is an optimization task, and **\"Gradient Boosting\" is one of many methods to perform optimization**. It uses a greedy approach and, therefore, may produce results that are not _globally_ optimal.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    & G_n(x) := \\text{the best base model from the family of the algorithms $\\mathcal{A}$} \\\\\n",
    "    & \\alpha_n(x) := \\text{scale or weight of the new model} \\\\\n",
    "    & f_N(x) = \\sum_{n=0}^N \\alpha_n (x) G_n(x) := \\text{the final composite model}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "### Gradient Boosting Algorithm\n",
    "\n",
    "Consider a loss function $\\mathcal{L}(y, \\hat{y})$ for a target $y$ and a prediction $\\hat{y}$, and let\n",
    "$(x_i, y_i)_{i = 1}^m$ be our train dataset for the regression task. \n",
    "\n",
    "\n",
    "1. Initialize $f_0(x) = z$ with the _flat constant prediction_\n",
    "\n",
    "$$z = \\arg\\min\\limits_{\\hat{y} \\in \\mathbb{R}} \\sum\\limits_{i = 1}^m \\mathcal{L}(y_i, \\hat{y})$$\n",
    "\n",
    "2. For $n$ from `1` to `n_boost_steps` do:\n",
    "    * Solve the current subporblem $L_n(G_n, \\alpha_n) \\to \\min\\limits_{G_{n}, \\alpha_n}$, where\n",
    "    \n",
    "    $$ L_n(G, \\alpha) = \\sum\\limits_{i = 1}^m \\mathcal{L}\\bigl(y_i, f_{n - 1}(x_i) + \\alpha G(x_i)\\bigr) $$\n",
    "    \n",
    "    with the following method:\n",
    "    \\begin{align}\n",
    "      & g_i = \\left. -\\frac{\\partial \\mathcal{L}(y_i, \\hat{y})}{\\partial \\hat{y}} \\right|_{\\hat{y} = G_{n - 1}(x_i)}\n",
    "          \\\\\n",
    "      & G_n(x) = \\arg\\min\\limits_{G \\in \\mathcal{A}}\\sum\\limits_{i = 1}^l \\bigl(G(x_i) - g_i\\bigr)^2\n",
    "          \\\\\n",
    "      & \\alpha_n = \\arg\\min\\limits_\\alpha L_n(G_n, \\alpha)\n",
    "          \\\\\n",
    "      & f_n(x) = f_{n - 1}(x) + \\alpha_n G_n(x)\n",
    "    \\end{align}\n",
    "    \n",
    "3. return $f_N(x) = f_0(x) + \\sum\\limits_{n = 1}^N \\alpha_n G_n(x)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96866b0",
   "metadata": {},
   "source": [
    "## Task 2. Gradient Boosting. [6 points]\n",
    "\n",
    "Assume that we've already found the optimal $G_n(x)$ at the step $n$ and we already have $f_{n-1}(x)$ from the previous step. Derive the expression for the **optimal value** of $\\alpha_n$ for the _MSE_ loss function $\\mathcal{L}(y, \\hat{y}) = (y - \\hat{y})^2$. Furthermore, explain what would happen to $\\alpha_n$ if the $|y_i - f_{n-1}(x_i)|$ values are close to 0 or significantly greater than $G_n(x_i)$ where $x_i$'s are data points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df9b45b",
   "metadata": {},
   "source": [
    "$\\color{red}{\\textbf{Your solution: }}$\n",
    "\n",
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc3086f",
   "metadata": {},
   "source": [
    "## Task 3. AdaBoost Weight Updates [3 points]\n",
    "\n",
    "$\\alpha_m$ parameter in AdaBoost update goes to infinity when ${err}_m$ goes to 0. What are the implications of this?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fea010",
   "metadata": {},
   "source": [
    "$\\color{red}{\\textbf{Your solution: }}$\n",
    "\n",
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7459999",
   "metadata": {},
   "source": [
    "## Task 4. Expectation Maximization (EM) [4 points]\n",
    "\n",
    "Prove that the following equation hold\n",
    "\n",
    "$max(\\sum\\limits_{i}logp(x^{(i)}; \\theta)) \\geq max(\\sum\\limits_{i}\\sum\\limits_{z^{(i)}} Q_i(z^{i})log\\frac{p(x^{(i)}, z^{(i)}; \\theta)}{Q_i(z^{(i)})})$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e879b94",
   "metadata": {},
   "source": [
    "$\\color{red}{\\textbf{Your solution: }}$\n",
    "\n",
    "-----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca9f5f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
